{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47c5411",
   "metadata": {},
   "source": [
    "# First RDD ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22519c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to \"find\" spark, as the name suggests\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c56b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use RDD we must first create a Spark session and Spark context\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d382987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Spark Session\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[4]\") \\\n",
    ".appName(\"WordCount_RDD\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5791435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Spark Context\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b328465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your path and read the txt\n",
    "\n",
    "path = \"C:\\\\Users\\\\seman\\\\Desktop\\\\PySpark\\\\Pyspark_WordCount_RDD\\\\omer_seyfettin_forsa_hikaye.txt\"\n",
    "story_rdd = sc.textFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ea55ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the number of rows in the document\n",
    "\n",
    "story_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6e1efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ömer Seyfettin - Forsa',\n",
       " '',\n",
       " 'Akdeniz’in, kahramanlık yuvası sonsuz ufuklarına bakan küçük tepe, minimini bir çiçek ormanı gibiydi. İnce uzun dallı badem ağaçlarının alaca gölgeleri sahile inen keçiyoluna düşüyor, ilkbaharın tatlı rüzgârıyla sarhoş olan martılar, çılgın bağrışlarıyla havayı çınlatıyordu. Badem bahçesinin yanı geniş bir bağdı. Beyaz taşlardan yapılmış kısa bir duvarın ötesindeki harabe vadiye kadar iniyordu. Bağın ortasındaki yıkık kulübenin kapısız girişinden bir ihtiyar çıktı. Saçı sakalı bembeyazdı. Kamburunu düzeltmek istiyormuş gibi gerindi. Elleri, ayakları titriyordu. Gök kadar boş, gök kadar sakin duran denize baktı, baktı.',\n",
       " '',\n",
       " '– Hayırdır inşallah! dedi.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brings first 5 rows of the document\n",
    "\n",
    "story_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b553954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap performs defined peration on each row in the document\n",
    "\n",
    "words = story_rdd.flatMap(lambda row: row.split(\" \")) # split according to space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ab5c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ömer',\n",
       " 'Seyfettin',\n",
       " '-',\n",
       " 'Forsa',\n",
       " '',\n",
       " 'Akdeniz’in,',\n",
       " 'kahramanlık',\n",
       " 'yuvası',\n",
       " 'sonsuz',\n",
       " 'ufuklarına']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at words\n",
    "\n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea05264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count words, we will start by appending 1 next to each and making them a tuple\n",
    "\n",
    "word_count = words.map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c3f73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4063ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ömer', 1), ('Seyfettin', 1), ('-', 1), ('Forsa', 1), ('', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daaee14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will reduce them by key - meaning : keys will be words and values will be number of times it occurs in the document\n",
    "\n",
    "word_count_RBK = word_count.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da10aa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ömer', 1), ('Seyfettin', 1), ('Forsa', 1), ('', 59), ('Akdeniz’in,', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_RBK.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3ce1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's take the numbers as first element in tuple\n",
    "\n",
    "word_count_RBK2 = word_count_RBK.map(lambda x: (x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31c1146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Ömer'), (1, 'Seyfettin'), (1, 'Forsa'), (59, ''), (1, 'Akdeniz’in,')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_RBK2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4381404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(59, ''),\n",
       " (33, 'bir'),\n",
       " (31, '–'),\n",
       " (8, 'yıl'),\n",
       " (6, 'diye'),\n",
       " (5, 'Türk'),\n",
       " (5, 'dedi.'),\n",
       " (5, 'onun'),\n",
       " (5, 'doğru'),\n",
       " (5, 'Kırk')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's sort them in descending order\n",
    "# 10 most common words are listed \n",
    "\n",
    "word_count_RBK2.sortByKey(False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e6f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {
    "height": "92px",
    "width": "168px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "446.222px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
